---
title: "QC and Sample Size Estimation"
author: "Witold E. Wolski"
date: "`r Sys.Date()`"
output: html_document
vignette: >
  %\VignetteIndexEntry{QC and Sample Size Estimation} 
  %\VignetteEncoding{UTF-8}
  %\VignetteEngine{knitr::rmarkdown}
editor_options: 
  chunk_output_type: console
bibliography:
  - prolfqua.bib
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, message = FALSE, warning = FALSE)
```

# Purpose
In this vignette we demonstrate how several descriptive statistics or diagnostic quality control plots can be generated for a dataset. For this, a proteinGroups file from the MaxQuant software is read and the "prolfqua specific" configuration is set up.
Afterwards a first look into the data, is transformed and normalized and some useful plots are illustrated for the full dataset. 
While then filtering to only one single condition with four replicates we want to estimate how many samples are necessairy to properly quantify a two-fold change for 90% of all the proteins with a power of 0.8.

# Loading data

Load the data from MaxQuant. In this case here we direclty load protein level data from the proteinGroups.txt file.

```{r LoadDataAndConfigure}
datadir <- file.path(find.package("prolfqua"), "samples/maxquant_txt")
inputMQfile <- file.path(datadir, "tiny2.zip")
inputAnnotation <- file.path(datadir, "annotation_Ionstar2018_PXD003881.xlsx")
startdata <- prolfqua::tidyMQ_ProteinGroups(inputMQfile)
```

Read the annotation with the meta information that is associated with the samples.

```{r readAnnotation}
annotation <- readxl::read_xlsx(inputAnnotation)
```


```{r joinAnnoAndData}
startdata <- dplyr::inner_join(annotation, startdata, by = "raw.file")
startdata |> head()
```

First, we want to remove all proteins identified only by a single peptide.

```{r filterForOnePeptide}
startdata <- startdata |> dplyr::filter(nr.peptides > 1)
```


We need to _tell_ `prolfqua` which columns in the table contain what information. This is done using the `AnalysisTableAnnotation` class.

The `hierarchy` describes the structure of the MS data. In this case we have only protein level measurements and therefore `hierarchyDepht` is equal to $1$.
In addition you need to describe the factors of the analysis, i.e, the column containing the explanatory variables which in this benchmark dataset is the dilution specified as sample in the annotation table.
You also need to specify the column containing the protein identifiers and the protein intensities.


```{r setupAnalysisTableAnnotation}
atable <- prolfqua::AnalysisTableAnnotation$new()
atable$fileName <- "raw.file"
atable$hierarchy[["protein_Id"]] <- c("proteinID")
atable$hierarchyDepth <- 1
atable$set_response("mq.protein.intensity")
atable$factors[["dilution."]] <- "sample"
atable$factors[["Run_ID"]] <- "run_ID"
atable$factorDepth <- 1

config <- prolfqua::AnalysisConfiguration$new(atable)

adata <- prolfqua::setup_analysis(startdata, config)
```


Further steps are the creation of the LFQData class instance and the usual standard preprocessing such as the removal of zeros from data.

```{r filterdata}
lfqdata <- prolfqua::LFQData$new(adata, config)
lfqdata$remove_small_intensities()
```

You can convert the data into a data frame in a wide format, where the
intensities of each sample occupy their columns.

```{r showHowToWide}
lfqdata$to_wide()$data[1:3, 1:8]
```

## Visualization of not normalized data

Next we show how the data is distributed before transformation and normalization.

```{r intensityDistribution}
lfqplotter <- lfqdata$get_Plotter()
lfqplotter$intensity_distribution_density()
```

### Visualization of missing data

Often it also makes sense to look into the part of the data that is not quantified in all samples. Therefore several functions for the missingess are available. In the `NA_heatmap` function it is possible to see if some missing proteins are specific for one particular dilution or if they appear randomly in all samples.

```{r makeMissingHeatmap}
nah <- lfqplotter$NA_heatmap()
```

Prints missing heatmap:
```{r printMissingHeatmap, fig.cap="Heatmap, black - missing protein intensities, white - present"}
nah
```

Also in the next two figures we show how many missing values are found in the respective conditions and how many proteins do not have missing data and how complete the measurements are for each group.

```{r summaryPerGroup, fig.cap="# of proteins with 0,1,...N missing values"}
lfqdata$get_Summariser()$plot_missingness_per_group()
```

```{r cumSumSummary, fig.cap="Cumulative sum of the # of proteins with 0,1,...N missing values"}
lfqdata$get_Summariser()$plot_missingness_per_group_cumsum()
```

In the `missigness_histogram` we can check if there is a dependency between NAs (and the number of NAs for earch protein) with respect to the protein intensity.

```{r missingnessHist, fig.cap="Intensity distribution of proteins depending on # of missing values"}
lfqplotter$missigness_histogram()
```

# Computing standard deviations, mean and CV.

Other important statistics that can be easily calculated from the object are coefficient of variation, means and standard deviations.

```{r PlotCVDistributions}
stats <- lfqdata$get_Stats()
prolfqua::table_facade(stats$stats_quantiles()$wide, paste0("quantile of ", stats$stat))
```


```{r cvDistr, fig.cap="Distribution of CV's"}
stats$density_median()
```

In the next figure we show the dependency of the standard deviation with respect to the mean intensitiy of the proteins.

```{r stdvVSmean, fig.cap="Scatter plot of standard deviation vs mean"}
stdm_raw <- stats$stdv_vs_mean(size = 10000) +
  ggplot2::scale_x_log10() +
  ggplot2::scale_y_log10()
stdm_raw
```


## Normalize protein intensities

Next, we want to normalize the data by first $\log_2$ transforming it and then z-scaling.
The $log_2$ stabilizes the variance, while the z-scaling removes systematic differences from the samples.

```{r normalizeData}
lt <- lfqdata$get_Transformer()
transformed <- lt$log2()$robscale()$lfq
transformed$config$table$is_response_transformed
```

Again we want to look into the distribution of the intensities in our samples after normalization.

```{r plotDensities, fig.cap="Normalized intensities."}
pl <- transformed$get_Plotter()
pl$intensity_distribution_density()
```

plots matrix scatter plot in the upper right matrix and some statistics in the
lower left matrix.

```{r plotScatterMatrix, fig.cap = "Scatterplot matrix"}
pl$pairs_smooth()
```

plots protein heatmap:
```{r plotheatmap, fig.cap="Heatmap, Rows - proteins, Columns - samples", fig.align=5, fig.height=5}
p <- pl$heatmap()
p
```

We can also look at the correlation among the samples or look at a PCA plot.

```{r heatmapCor}
hc <- pl$heatmap_cor()
```

```{r plotHeatmapCor, fig.cap="Heatmap based on sample correlations, Rows - samples, Columns - samples", fig.align=5, fig.height=5}
hc
```

```{r doPCA, fig.cap="Principal component analysis for all samples", fig.align=5, fig.height=7}
pl$pca()
```

prints the standard deviations:
```{r showStandardDeviations}
stats <- transformed$get_Stats()
prolfqua::table_facade(stats$stats_quantiles()$wide, "Standard deviations")
```


plots density of the standard deviation

```{r sddensity, fig.cap="Density of the standard deviation"}
stats$density_median()
```

TODO(WEW): Please describe the figure.

```{r experiment, include = FALSE}
chsq <- na.omit(stats$statsdf$sd^2)
plot(density(chsq[chsq < 10]))
x <- seq(0, 50, length = 1000)
lines(x * median(chsq), dchisq(x, df = 4), col = 2)
```

Check for heteroskedasticity. After transformation,
the standard deviation should be independent of the mean intensity.

```{r checkForHeteroskedasticity, fig.cap="Scatter plot of sd vs mean of protein intensity"}
stdm_trans <- stats$stdv_vs_mean(size = 10000) + ggplot2::scale_x_log10() + ggplot2::scale_y_log10()
stdm_trans
# gridExtra::grid.arrange(stdm_raw, stdm_trans, nrow=1)
```


## Estimate sample size

For the sample size estimation we will now focus on only one condition and the different bio-reps from the _a_ dilution.
In this condition all samples have the same concentration and we want to check variability within this group. 
Like this we can estimate how many samples are necessary per group to quantify properly a two-fold change (delta of 1) for 90% of all the proteins with a power of 0.8 and significance level of 0.05.

First, we need to filter our data for `dilution.` _a_ only.
```{r}
# startdata <- startdata |> dplyr::filter(sample  == "a")
transformedA <- transformed$get_copy()
transformedA$data <- transformedA$data |> dplyr::filter(dilution. == "a")
stats <- transformedA$get_Stats()
```

```{r fig.cap="Empirical cumulative density function of the standard deviation for all the proteins in the dataset."}
stats$density(ggstat = "ecdf")
```

The table indicates that for this kind of data - if a two-fold change for 90% of all the proteins should be accurately quantified with a power of 0.8 (at 0.05 significance level) one would need to have 10 samples in each group.

```{r estimateSampleSizes}
sampleSize <- stats$power_t_test_quantiles() |>
  dplyr::filter(dilution. != "All")
prolfqua::table_facade(sampleSize, "Sample sizes. delta - Effect size, N - samplesize")
```

The table summarises visually how many samples are needed for different expected differences (in log2-scale) and different portions of all proteins. 

```{r fig.cap="Estimated sample sizes for various FC levels and various quantiles of the standard deviation."}
sampleSize |>
  ggplot2::ggplot(ggplot2::aes(x = factor(probs), y = N)) +
  ggplot2::facet_wrap(~delta) +
  ggplot2::geom_bar(stat = "identity")
```

It is also possible to get the statistics for each protein in each group. The information includes group size, number of observations, standard deviation, variance, mean.

```{r stats, eval = TRUE}
stats$stats() |> head()
```

You can also estimate the sample size needed to perform differential expression analysis for each protein, given the `power`, `delta`, and `sig.level`.
The next figure shows the distribution of needed sample sizes for all proteins with a power of 0.8 at signifiance level 0.05 for a two fold change (delta = 1).

```{r statsWithN, eval = TRUE}
x <- stats$power_t_test(delta = 1, power = 0.8, sig.level = 0.05)
x <- x |>
  dplyr::filter(dilution. == "a") |>
  dplyr::arrange(desc(N), protein_Id)
prolfqua::table_facade(x[1:7, ], caption = "Sample size for each protein")
```


```{r fig.cap="Distribution of the required sample sizes for two fold change thresholds for all the proteins."}
x |> ggplot2::ggplot(ggplot2::aes(x = N)) +
  ggplot2::geom_histogram() +
  ggplot2::facet_wrap(~delta) +
  ggplot2::xlim(0, 100)
```

The `prolfqua` package is described in [@Wolski2022.06.07.494524].

# Session Info

```{r}
sessionInfo()
```

# References
