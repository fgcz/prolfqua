---
title: "Summarize Peptide Level Measurements"
author: "WEW@FGCZ.ETHZ.CH"
date: "`r Sys.Date()`"
output:
  pdf_document: default
  html_document: default
params:
  configuration:  !r quote(LFQService::skylineconfig)
  data: !r quote(LFQService::sample_analysis)
  plot_density: TRUE
  plot_sd_vs_mean: FALSE
vignette: >
  %\VignetteIndexEntry{Summarize Peptide Level Measurements}
  %\VignetteEncoding{UTF-8}
  %\VignetteEngine{knitr::rmarkdown}
editor_options:
  chunk_output_type: console
---



```{r setup, include=FALSE}
library(tidyverse)
library(LFQService)

knitr::opts_chunk$set(echo = FALSE, message=FALSE, warning = FALSE, fig.with = 8, fig.height = 4)
data <- eval(params$data)
config <- eval(params$configuration)


if(is.null(params$plot_density)){
  params$plot_density <- TRUE
}
if(is.null(params$plot_sd_vs_mean)){
  params$plot_sd_vs_mean <- FALSE
}
old <- theme_set(theme_classic())

```

# Summarize dataset

```{r sampleNameRawFileMapping}
#xx<-table_factors(pepIntensity,config)
#xx %>% dplyr::group_by_at(config$table$factorKeys()) %>%  dplyr::summarize(n=n())
knitr::kable(table_factors(data,config), caption = "Sample Name to Raw file mapping")

```

```{r hierarchyCounts}
x <- hierarchyCounts( data , config )
knitr::kable(data.frame(NR = x), caption="Number of peptides and proteins")
```


```{r hierarchyCountsSample }
knitr::kable(hierarchy_counts_sample(data, configuration = config), caption = "Number of quantified peptides and proteins per sample.")
```

```{r hierarchyCountsSampleBarplot, fig.cap="Number of quantified peptides and proteins per sample."}
hcs <- hierarchy_counts_sample(data, configuration = config)
LFQService::skylineconfig$table$sampleName
hcs <- hcs %>% tidyr::gather("key", "nr",
                      -dplyr::one_of(config$table$isotopeLabel, config$table$sampleName))
ggplot(hcs, aes(x = sampleName, y = nr)) + geom_bar(stat="identity", position="dodge") + 
  facet_wrap(~key, scales = "free_y", ncol=1) + theme(axis.text.x = element_text(angle = 90, hjust = 1))

```


```{r proteinSummaries}
data <- LFQService::remove_small_intensities(data, config)
data <- LFQService::completeCases(data,config)

x3 <- summarizeHierarchy(data, config)
x3 <- x3 %>% dplyr::mutate(protein_with = case_when(peptide_Id_n == 1 ~ "one",
                                             peptide_Id_n > 1 ~ "two and more"))

res <- x3 %>% dplyr::group_by(protein_with) %>% dplyr::summarize(n=n())
knitr::kable(res, caption = "nr of proteins with more than on peptide.")
```

```{r, fig.height=3, fig.with=4, fig.cap="Number of proteins with one or more peptides."}
ggplot(x3, aes(x = protein_with)) + geom_bar(stat="count")
```

```{r filterOnPeptideNr}
x3 %>% dplyr::filter(peptide_Id_n >= config$parameter$min_peptides_protein) -> x4
data <- inner_join(data, x4, by=config$table$hkeysLevel())
```


```{r missingFigIntensityHistorgram, fig.width=7, fig.height=7, fig.cap="Top - intensity distribution of peptides with 0, 1 etc. missing values. B - number of peptides with 0,1,2 etc. mssing value."}
p <- missignessHistogram(data, config)
xx1 <- missingPerCondition(data, config)
xx2 <- missingPerConditionCumsum(data, config)
gridExtra::grid.arrange(p, xx1$figure, xx2$figure, ncol=1)

```


```{r missignessHistogram, fig.cap="Missingness patterns.", fig.width=7, fig.height=8}
if(FALSE){
  plot_NA_heatmap(data, config)
}
```

\clearpage


# Summarize Quantification

## Raw Intensity Distribution

```{r plotDistributions, fig.cap="Density plot of peptide level Coefficient of Variations (CV)."}
stats_res <- summarize_cv(data, config)
if(params$plot_density){
  p1 <- LFQService::plot_stat_density(stats_res, config, stat="CV") + labs(tag = "A") + xlim(0, 150)
  p2 <- LFQService::plot_stat_density_median(stats_res, config, stat="CV") + labs(tag = "B") + xlim(0, 150)
  gridExtra::grid.arrange(p1,p2)
}else{
  p1 <- LFQService::plot_stat_violin(stats_res, config, stat="CV") + labs(tag='A')
  p2 <- LFQService::plot_stat_violin_median(stats_res, config, stat="CV") + labs(tag='B')
  gridExtra::grid.arrange(p1,p2)
}
```

```{r}
if(params$plot_sd_vs_mean){
  p0 <-plot_stdv_vs_mean(stats_res, config)  + labs(tag='A') # takes to long to plot.
}
```

```{r computeCVQuantiles, include=FALSE}
toQuantiles <- function(x,probs=c(0.1,0.25,0.5,0.75,0.9)){ 
  tibble(probs = probs, quantiles = quantile(x, probs , na.rm = T)) 
}

stats_res %>% dplyr::group_by(!!sym(config$table$factorKeys()[1])) %>% tidyr::nest() -> xx 
xx %>% dplyr::mutate(cv_quantiles = map(data, ~toQuantiles(.$CV) )) %>%
  dplyr::select(!!sym(config$table$factorKeys()[1]), cv_quantiles) %>%
  tidyr::unnest() %>%
  spread(!!sym(config$table$factorKeys()[1]),quantiles) -> cv_quantiles_res

```


```{r printTable}
knitr::kable(cv_quantiles_res, caption="CV at 0.1, 0.25, 0.5, 0.75, 0.9 quantiles.")
```



```{r intensityDistribution, fig.cap="Not normalized intensity distribution.", fig.height=10, fig.width=10}
if(params$plot_density){
  p0 <- LFQService::plot_intensity_distribution_density(data,config)  + theme(legend.text=element_text(size=5))
  p0
} else{
  p1 <- LFQService::plot_intensity_distribution_violin(data,config)
  p1
}

```



## Transformed Intensity Distribution

We apply the `LFQService::robust_scale` transformation to the data. This transformation transfroms and scales the data to reduce the variance.
Because of this, we can't report CV anymore but report standard deviations.

```{r transformIntensities}
data <- LFQService::transform_work_intensity(data, config,  log2 )
dataTransformed <- LFQService::applyToIntensityMatrix(data, config, robust_scale)
config$parameter$is_intensity_transformed = TRUE
```


```{r sdviolinplots,fig.cap="Visualization of peptide standard deviations. A) all. B) - for low (bottom 50) and high intensity peptides (top 50)."}
stats_res <- summarize_cv(dataTransformed, config)

if(params$plot_density){
  p1 <- LFQService::plot_stat_density(stats_res, config, stat="sd") + labs(tag = "A") + xlim(0, 2)
  p2 <- LFQService::plot_stat_density_median(stats_res, config, stat="sd") + labs(tag = "B") + xlim(0, 2)
  gridExtra::grid.arrange(p1,p2)
}else{
  p1 <- LFQService::plot_stat_violin(stats_res, config, stat="sd") + labs(tag = "A")
  p2 <- LFQService::plot_stat_violin_median(stats_res, config, stat="sd") + labs(tag = "B")
  gridExtra::grid.arrange(p1,p2)
}
```


```{r fig.cap="Standard Deviation vs Mean"}
if(params$plot_sd_vs_mean){
  p0 <- plot_stdv_vs_mean(stats_res, config) + labs(tag="A")
}
```

```{r computeSDQuantiles, include=FALSE}
toQuantiles <- function(x,probs=c(0.1,0.25,0.5,0.75,0.9)){ 
  tibble(probs = probs, quantiles = quantile(x, probs , na.rm = T)) 
}

stats_res %>% dplyr::group_by(!!sym(config$table$factorKeys()[1])) %>% tidyr::nest() -> xx 
xx %>% dplyr::mutate(sd_quantiles = map(data, ~toQuantiles(.$sd) )) %>%
  dplyr::select(!!sym(config$table$factorKeys()[1]), sd_quantiles) %>%
  tidyr::unnest() %>%
  spread(!!sym(config$table$factorKeys()[1]),quantiles) -> sd_quantiles_res

```


```{r printSDTable}
knitr::kable(sd_quantiles_res, caption="standard deviation at 0.1, 0.25, 0.5, 0.75, 0.9 quantiles.")
```



```{r plotTransformedIntensityDistributions, fig.cap="Peptide intensity distribution after transformation.", fig.width=10, fig.height=10}
if(params$plot_density){
  p1 <- LFQService::plot_intensity_distribution_density(dataTransformed,config) + theme(legend.text=element_text(size=5))
  p1
} else{ 
  p2 <- LFQService::plot_intensity_distribution_violin(dataTransformed,config) 
  p2
}
```

\clearpage



```{r correlationHeat, fig.height = 5, fig.cap="Heatmap of peptide intensity correlation between samples"}
plot_heatmap_cor(dataTransformed,config)
```


```{r overviewHeat, fig.cap="Sample and peptide/protein Heatmap."}
if(params$plot_sd_vs_mean){
  plot_heatmap(dataTransformed,config)
}
```

\clearpage

# Sample Size Calculation for peptide level data.

We estimated the _Variance_ of the measurement using the QC samples. For each protein we can compute the standard deviation based on the 4 QC samples. The distribution of the standard deviations is shown in Figure \@ref(fig:sdviolinplots).

This allows us to calculate the required sample size n. The table \@ref(sampleSize) summarizes how many samples are needed to detect a fold change of 2 at a significance level of $1-0.05$ and power of $0.8$ for $25, 50, 75, 90$ percent of the proteins.


```{r sampleSize}
sampleSize <- lfq_power_t_test(dataTransformed, config, delta=2)
knitr::kable(sampleSize, caption="Sample size needed to report a fold change greater than 2 with a significance level of 0.05 and power 0.8 when using t-test to compare means.")
```


The _power_ of a test is $1-\beta$, where $beta$ is the probability of a Type 2 error (failing to reject the null hypothesis when the alternative hypothesis is true).
In other words, if you have a $20\%$ chance of failing to detect a real difference, then the power of your test is $.8$.

_Significance_ is equal to $1 - \alpha$, where $\alpha$ is the probability of making a Type 1 Error. That is, alpha represents the chance of a falsely rejecting H0 and picking up a false-positive effect. Alpha is usually set at 0.05, for a $95\%$ significance.


Fold change : Suppose you are comparing a treatment group to a placebo group, and you will be measuring some continuous response variable which, you hope, will be affected by the treatment. We can consider the mean response in the treatment group, $\mu_1$, and the mean response in the placebo group, $\mu_2$. We can then define $\Delta = \mu_1 â€“ \mu_2$. The smaller the difference you want to detect, the larger the required sample size.
